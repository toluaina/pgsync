#!/usr/bin/env python

"""Create a custom NGram analyzer for the default mapping."""
import json
import logging

import click
from elasticsearch import Elasticsearch, helpers

from pgsync.settings import ELASTICSEARCH_TIMEOUT, ELASTICSEARCH_VERIFY_CERTS
from pgsync.utils import get_config, get_elasticsearch_url, timeit

logger = logging.getLogger(__name__)

NGRAM_ANALYZER = {
    'analysis': {
        'analyzer': {
            'ngram_analyzer': {
                'filter': [
                    'lowercase',
                ],
                'type': 'custom',
                'tokenizer': 'ngram_tokenizer',
            },
        },
        'tokenizer': {
            'ngram_tokenizer': {
                'token_chars': [
                    'letter',
                    'digit',
                    'punctuation',
                    'symbol',
                ],
                'min_gram': '3',
                'type': 'ngram',
                'max_gram': '10',
            },
        },
    },
    'max_ngram_diff': 10,
}


def apply_analyzer_to_mapping(mapping, analyzer):
    _mapping = {}
    for key, value in mapping.items():
        if isinstance(value, dict):
            if 'fields' in value:
                value['fields']['ngram'] = analyzer
            value = apply_analyzer_to_mapping(value, analyzer)
        _mapping[key] = value
    return _mapping


def get_configuration(es, index):
    configuration = es.indices.get_settings(index)[index]
    # skip these attributes
    for key in [
        'uuid',
        'version',
        'provided_name',
        'creation_date',
    ]:
        configuration['settings']['index'].pop(key)
    mapping = es.indices.get_mapping(index)
    analyzer_mapping = apply_analyzer_to_mapping(
        mapping,
        {
            'analyzer': 'ngram_analyzer',
            'search_analyzer': 'ngram_analyzer',
            'fielddata': True,
            'type': 'text',
        }
    )
    configuration.update(**analyzer_mapping[index])
    configuration['settings']['index'].update(**NGRAM_ANALYZER)
    return configuration


@timeit
def create_es_mapping(index):
    logger.debug(f'Create Elasticsearch mapping for index {index}')
    url = get_elasticsearch_url()
    es = Elasticsearch(
        hosts=[url],
        timeout=ELASTICSEARCH_TIMEOUT,
        verify_certs=ELASTICSEARCH_VERIFY_CERTS,
    )

    tmp_index = 'tmp_index'
    es.indices.delete(index=tmp_index, ignore=[400, 404])
    es.indices.refresh()
    configuration = get_configuration(es, index)
    es.indices.create(index=tmp_index, body=configuration)
    helpers.reindex(es, index, tmp_index)
    es.indices.refresh()
    es.indices.delete(index=index)
    es.indices.refresh()
    configuration = get_configuration(es, tmp_index)
    es.indices.create(index=index, body=configuration)
    helpers.reindex(es, tmp_index, index)
    es.indices.delete(index=tmp_index)
    es.indices.refresh()


@click.command()
@click.option(
    '--config',
    '-c',
    help='Schema config',
    type=click.Path(exists=True),
)
def main(config):
    """Create custom NGram analyzer for the default mapping."""

    config = get_config(config)
    for index in set([
        document['index'] for document in json.load(
            open(config)
        )
    ]):
        create_es_mapping(index)


if __name__ == '__main__':
    main()
